{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7jjYY8dEtxsO"
   },
   "source": [
    "# Serverless Example\n",
    "## Tensorflow 2.0 [ CLASSIFICATION ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YM_al1Aytxsg"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7181,
     "status": "ok",
     "timestamp": 1562621344664,
     "user": {
      "displayName": "Fabio Mardero",
      "photoUrl": "",
      "userId": "01769998706955373091"
     },
     "user_tz": -120
    },
    "id": "7vLo_dyQtxsi",
    "outputId": "892bbf0e-7195-4f4d-e532-c77e3b94b2c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.0.0-beta1 in /usr/local/lib/python3.6/dist-packages (2.0.0b1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.14.6)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.15.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.0.8)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.12.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.7.1)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.11.2)\n",
      "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.14.0.dev2019060501)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.8.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.33.4)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.2.2)\n",
      "Requirement already satisfied: tb-nightly<1.14.0a20190604,>=1.14.0a20190603 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.14.0a20190603)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.1.7)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (3.7.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-beta1) (2.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (3.1.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (41.0.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (0.15.4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.0.0-dev20190708'"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load some dependencies\n",
    "!pip install tensorflow==2.0.0-beta1\n",
    "!pip install -q tf-nightly-2.0-preview\n",
    "\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from collections import OrderedDict\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cUuFN9z0txsp"
   },
   "source": [
    "### Load database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ryziQ9vutxsr"
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xbkc6cvaoNRo"
   },
   "source": [
    "## Training Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_qHjAG0PtxtE"
   },
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AdkPKYN-txtF"
   },
   "outputs": [],
   "source": [
    "def my_model(input_size):\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # Create a custom model using tf.keras\n",
    "    inputs = tf.keras.layers.Input(shape=(input_size))\n",
    "    x = tf.keras.layers.Dense(8, activation='relu')(inputs)\n",
    "    x = tf.keras.layers.Dense(4, activation='relu')(x)\n",
    "    outputs = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = my_model(X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tB9MWFEK0Lo6"
   },
   "source": [
    "### Training\n",
    "Time to train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8368,
     "status": "ok",
     "timestamp": 1562621345901,
     "user": {
      "displayName": "Fabio Mardero",
      "photoUrl": "",
      "userId": "01769998706955373091"
     },
     "user_tz": -120
    },
    "id": "TeCCAoSptxtK",
    "outputId": "a888b0d8-435b-4a33-c03b-25284183aedd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 2.3787 - accuracy: 0.4167 - val_loss: 2.1323 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 0s 331us/sample - loss: 2.0144 - accuracy: 0.4167 - val_loss: 1.6324 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 0s 353us/sample - loss: 1.7121 - accuracy: 0.4167 - val_loss: 1.2178 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 0s 362us/sample - loss: 1.4677 - accuracy: 0.4167 - val_loss: 0.9829 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 0s 346us/sample - loss: 1.2753 - accuracy: 0.4750 - val_loss: 0.8397 - val_accuracy: 0.2667\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 0s 367us/sample - loss: 1.1123 - accuracy: 0.5583 - val_loss: 0.7658 - val_accuracy: 0.8333\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 0s 228us/sample - loss: 0.9816 - accuracy: 0.5750 - val_loss: 0.7778 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 0s 252us/sample - loss: 0.8867 - accuracy: 0.5750 - val_loss: 0.8631 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 0s 253us/sample - loss: 0.8222 - accuracy: 0.6000 - val_loss: 0.9224 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 0s 224us/sample - loss: 0.7867 - accuracy: 0.6750 - val_loss: 0.9353 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "def training(model, X, y):\n",
    "    # Compile the model specifying optimizer, metrics and learning rate\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])    \n",
    "\n",
    "    # A useful callback\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint('model.hdf5', save_best_only=True)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(x=X,\n",
    "              y=y,\n",
    "              validation_split=0.2,\n",
    "              batch_size=8,\n",
    "              epochs=10,\n",
    "              callbacks=[checkpoint],\n",
    "              verbose=1)\n",
    "    \n",
    "    # Load the best model\n",
    "    model = tf.keras.models.load_model('model.hdf5')\n",
    "    return model\n",
    "    \n",
    "\n",
    "best_model = training(model, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LftA3nhve6PX"
   },
   "source": [
    "## Testing Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q-jZ8EkaxbtM"
   },
   "source": [
    "### Blank paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "erVN8hRIlRac"
   },
   "outputs": [],
   "source": [
    "# Lets put us in blank paper condition\n",
    "del best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4B7kGwM9xfjd"
   },
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9034,
     "status": "ok",
     "timestamp": 1562621346593,
     "user": {
      "displayName": "Fabio Mardero",
      "photoUrl": "",
      "userId": "01769998706955373091"
     },
     "user_tz": -120
    },
    "id": "i6_1pxETlJqv",
    "outputId": "904b817d-d846-4a4d-8466-4958d367f260"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  import sys\n",
      "W0708 21:28:56.484899 140050027865984 <ipython-input-12-852f5552e1c1>:24] predicted: ['setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'virginica', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'virginica', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'setosa', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'setosa', 'setosa', 'virginica', 'virginica', 'virginica', 'setosa', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'setosa', 'virginica', 'virginica', 'setosa', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger = logging.getLogger('iris')\n",
    "\n",
    "\n",
    "## Prediction \n",
    "def handle(event, **kwargs):\n",
    "    # If data is received as json convert to pandas\n",
    "    event = event['data'] if 'data' in event else event\n",
    "    if not isinstance(event, pd.DataFrame):\n",
    "        event = pd.DataFrame.from_dict(event, orient='columns')\n",
    "\n",
    "    # Retrieve model from disk and use it for predictions\n",
    "    model = tf.keras.models.load_model('model.hdf5')\n",
    "    \n",
    "    # Target format convertion\n",
    "    target_dict = {0: 'setosa', 1: 'versicolor', 2:'virginica'}\n",
    "    to_target = np.vectorize(lambda x: target_dict[x])\n",
    "    \n",
    "    return to_target(np.argmax(model(event.values), axis=1)).tolist()\n",
    "\n",
    "## Testing and liveness check\n",
    "def test(data, **kwargs):\n",
    "    pred = handle(data)\n",
    "\n",
    "    logger.warning(f\"predicted: {pred}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "test(iris.data)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tensorflow_classification.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
