{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RNGwNhZFYDhE"
   },
   "source": [
    "# Serverless Example\n",
    "## PyTorch [CLASSIFICATION]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NqWvcF2p5XWQ"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "XEOXLqSyT2Ap",
    "outputId": "bf97e18c-e24d-4075-859c-d4bdd6bdb242"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install some dependencies\n",
    "!pip install torch\n",
    "\n",
    "\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use CPU or GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lSK1CO-O_IdH"
   },
   "source": [
    "### Load Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ja3-ZEDT7kFL"
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data.astype('float32')\n",
    "y = iris.target.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1N71slD65Eu4"
   },
   "source": [
    "## Training Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tn50X6xw5IxJ"
   },
   "source": [
    "### DataLoaders definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r0dWCplEjt-8"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "data_loader = DataLoader(dataset=TensorDataset(torch.from_numpy(X), torch.from_numpy(y)),\n",
    "                         batch_size=BATCH_SIZE, \n",
    "                         shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1mHw7MnCo4tf"
   },
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ddyvSCrbYRa9"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=4, out_features=5)\n",
    "        self.fc2 = nn.Linear(5, 4)\n",
    "        self.fc3 = nn.Linear(4, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.log_softmax(self.fc3(x), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "grFBmZ4Eh0bc"
   },
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "43Rksdr84_0D"
   },
   "source": [
    "### Training\n",
    "The model will give bad performances due to the lack of normalization of the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "dwqQe1yPODtF",
    "outputId": "5a575cf3-c869-4be6-8797-525dac30f23b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:   0 [  0/150 (0%)]\tLoss: 1.041497\n",
      "Train Epoch:   0 [  8/150 (5%)]\tLoss: 1.038754\n",
      "Train Epoch:   0 [ 16/150 (11%)]\tLoss: 1.200789\n",
      "Train Epoch:   0 [ 24/150 (16%)]\tLoss: 1.090870\n",
      "Train Epoch:   0 [ 32/150 (21%)]\tLoss: 1.055345\n",
      "Train Epoch:   0 [ 40/150 (26%)]\tLoss: 1.123244\n",
      "Train Epoch:   0 [ 48/150 (32%)]\tLoss: 1.080847\n",
      "Train Epoch:   0 [ 56/150 (37%)]\tLoss: 1.110489\n",
      "Train Epoch:   0 [ 64/150 (42%)]\tLoss: 1.067616\n",
      "Train Epoch:   0 [ 72/150 (47%)]\tLoss: 1.034437\n",
      "Train Epoch:   0 [ 80/150 (53%)]\tLoss: 1.041163\n",
      "Train Epoch:   0 [ 88/150 (58%)]\tLoss: 1.015485\n",
      "Train Epoch:   0 [ 96/150 (63%)]\tLoss: 1.282724\n",
      "Train Epoch:   0 [104/150 (68%)]\tLoss: 1.102610\n",
      "Train Epoch:   0 [112/150 (74%)]\tLoss: 1.001182\n",
      "Train Epoch:   0 [120/150 (79%)]\tLoss: 1.044164\n",
      "Train Epoch:   0 [128/150 (84%)]\tLoss: 1.025715\n",
      "Train Epoch:   0 [136/150 (89%)]\tLoss: 0.989628\n",
      "Train Epoch:   0 [108/150 (95%)]\tLoss: 0.984355\n",
      "Train Epoch:   1 [  0/150 (0%)]\tLoss: 1.044328\n",
      "Train Epoch:   1 [  8/150 (5%)]\tLoss: 0.994986\n",
      "Train Epoch:   1 [ 16/150 (11%)]\tLoss: 0.961217\n",
      "Train Epoch:   1 [ 24/150 (16%)]\tLoss: 0.994547\n",
      "Train Epoch:   1 [ 32/150 (21%)]\tLoss: 0.947874\n",
      "Train Epoch:   1 [ 40/150 (26%)]\tLoss: 0.970310\n",
      "Train Epoch:   1 [ 48/150 (32%)]\tLoss: 0.971714\n",
      "Train Epoch:   1 [ 56/150 (37%)]\tLoss: 0.931582\n",
      "Train Epoch:   1 [ 64/150 (42%)]\tLoss: 0.839098\n",
      "Train Epoch:   1 [ 72/150 (47%)]\tLoss: 0.904354\n",
      "Train Epoch:   1 [ 80/150 (53%)]\tLoss: 1.035820\n",
      "Train Epoch:   1 [ 88/150 (58%)]\tLoss: 0.990129\n",
      "Train Epoch:   1 [ 96/150 (63%)]\tLoss: 0.883036\n",
      "Train Epoch:   1 [104/150 (68%)]\tLoss: 0.809658\n",
      "Train Epoch:   1 [112/150 (74%)]\tLoss: 0.930037\n",
      "Train Epoch:   1 [120/150 (79%)]\tLoss: 0.887583\n",
      "Train Epoch:   1 [128/150 (84%)]\tLoss: 0.850290\n",
      "Train Epoch:   1 [136/150 (89%)]\tLoss: 0.882024\n",
      "Train Epoch:   1 [108/150 (95%)]\tLoss: 0.760876\n",
      "Train Epoch:   2 [  0/150 (0%)]\tLoss: 0.836066\n",
      "Train Epoch:   2 [  8/150 (5%)]\tLoss: 0.887571\n",
      "Train Epoch:   2 [ 16/150 (11%)]\tLoss: 0.791370\n",
      "Train Epoch:   2 [ 24/150 (16%)]\tLoss: 0.733173\n",
      "Train Epoch:   2 [ 32/150 (21%)]\tLoss: 0.716116\n",
      "Train Epoch:   2 [ 40/150 (26%)]\tLoss: 0.684009\n",
      "Train Epoch:   2 [ 48/150 (32%)]\tLoss: 0.773182\n",
      "Train Epoch:   2 [ 56/150 (37%)]\tLoss: 0.833116\n",
      "Train Epoch:   2 [ 64/150 (42%)]\tLoss: 0.773701\n",
      "Train Epoch:   2 [ 72/150 (47%)]\tLoss: 0.760881\n",
      "Train Epoch:   2 [ 80/150 (53%)]\tLoss: 0.720674\n",
      "Train Epoch:   2 [ 88/150 (58%)]\tLoss: 0.699506\n",
      "Train Epoch:   2 [ 96/150 (63%)]\tLoss: 0.750623\n",
      "Train Epoch:   2 [104/150 (68%)]\tLoss: 0.642844\n",
      "Train Epoch:   2 [112/150 (74%)]\tLoss: 0.784560\n",
      "Train Epoch:   2 [120/150 (79%)]\tLoss: 0.784358\n",
      "Train Epoch:   2 [128/150 (84%)]\tLoss: 0.686117\n",
      "Train Epoch:   2 [136/150 (89%)]\tLoss: 0.616237\n",
      "Train Epoch:   2 [108/150 (95%)]\tLoss: 0.512729\n",
      "Train Epoch:   3 [  0/150 (0%)]\tLoss: 0.934777\n",
      "Train Epoch:   3 [  8/150 (5%)]\tLoss: 0.559421\n",
      "Train Epoch:   3 [ 16/150 (11%)]\tLoss: 0.675839\n",
      "Train Epoch:   3 [ 24/150 (16%)]\tLoss: 0.722940\n",
      "Train Epoch:   3 [ 32/150 (21%)]\tLoss: 0.609685\n",
      "Train Epoch:   3 [ 40/150 (26%)]\tLoss: 0.540387\n",
      "Train Epoch:   3 [ 48/150 (32%)]\tLoss: 0.513578\n",
      "Train Epoch:   3 [ 56/150 (37%)]\tLoss: 0.493944\n",
      "Train Epoch:   3 [ 64/150 (42%)]\tLoss: 0.756389\n",
      "Train Epoch:   3 [ 72/150 (47%)]\tLoss: 0.561930\n",
      "Train Epoch:   3 [ 80/150 (53%)]\tLoss: 0.767941\n",
      "Train Epoch:   3 [ 88/150 (58%)]\tLoss: 0.725957\n",
      "Train Epoch:   3 [ 96/150 (63%)]\tLoss: 0.624085\n",
      "Train Epoch:   3 [104/150 (68%)]\tLoss: 0.642764\n",
      "Train Epoch:   3 [112/150 (74%)]\tLoss: 0.517526\n",
      "Train Epoch:   3 [120/150 (79%)]\tLoss: 0.604805\n",
      "Train Epoch:   3 [128/150 (84%)]\tLoss: 0.687675\n",
      "Train Epoch:   3 [136/150 (89%)]\tLoss: 0.610393\n",
      "Train Epoch:   3 [108/150 (95%)]\tLoss: 0.606248\n",
      "Train Epoch:   4 [  0/150 (0%)]\tLoss: 0.616245\n",
      "Train Epoch:   4 [  8/150 (5%)]\tLoss: 0.981006\n",
      "Train Epoch:   4 [ 16/150 (11%)]\tLoss: 1.187245\n",
      "Train Epoch:   4 [ 24/150 (16%)]\tLoss: 0.706705\n",
      "Train Epoch:   4 [ 32/150 (21%)]\tLoss: 0.531691\n",
      "Train Epoch:   4 [ 40/150 (26%)]\tLoss: 0.594516\n",
      "Train Epoch:   4 [ 48/150 (32%)]\tLoss: 0.453355\n",
      "Train Epoch:   4 [ 56/150 (37%)]\tLoss: 0.399535\n",
      "Train Epoch:   4 [ 64/150 (42%)]\tLoss: 0.447566\n",
      "Train Epoch:   4 [ 72/150 (47%)]\tLoss: 0.559755\n",
      "Train Epoch:   4 [ 80/150 (53%)]\tLoss: 0.551226\n",
      "Train Epoch:   4 [ 88/150 (58%)]\tLoss: 0.684952\n",
      "Train Epoch:   4 [ 96/150 (63%)]\tLoss: 1.299299\n",
      "Train Epoch:   4 [104/150 (68%)]\tLoss: 0.641597\n",
      "Train Epoch:   4 [112/150 (74%)]\tLoss: 0.503671\n",
      "Train Epoch:   4 [120/150 (79%)]\tLoss: 0.462155\n",
      "Train Epoch:   4 [128/150 (84%)]\tLoss: 0.937805\n",
      "Train Epoch:   4 [136/150 (89%)]\tLoss: 0.543324\n",
      "Train Epoch:   4 [108/150 (95%)]\tLoss: 0.472470\n",
      "Train Epoch:   5 [  0/150 (0%)]\tLoss: 0.484384\n",
      "Train Epoch:   5 [  8/150 (5%)]\tLoss: 0.735427\n",
      "Train Epoch:   5 [ 16/150 (11%)]\tLoss: 0.549513\n",
      "Train Epoch:   5 [ 24/150 (16%)]\tLoss: 0.517420\n",
      "Train Epoch:   5 [ 32/150 (21%)]\tLoss: 0.520582\n",
      "Train Epoch:   5 [ 40/150 (26%)]\tLoss: 0.868075\n",
      "Train Epoch:   5 [ 48/150 (32%)]\tLoss: 0.643423\n",
      "Train Epoch:   5 [ 56/150 (37%)]\tLoss: 0.448780\n",
      "Train Epoch:   5 [ 64/150 (42%)]\tLoss: 0.461800\n",
      "Train Epoch:   5 [ 72/150 (47%)]\tLoss: 0.495561\n",
      "Train Epoch:   5 [ 80/150 (53%)]\tLoss: 0.289407\n",
      "Train Epoch:   5 [ 88/150 (58%)]\tLoss: 0.348780\n",
      "Train Epoch:   5 [ 96/150 (63%)]\tLoss: 0.475520\n",
      "Train Epoch:   5 [104/150 (68%)]\tLoss: 0.246360\n",
      "Train Epoch:   5 [112/150 (74%)]\tLoss: 0.555321\n",
      "Train Epoch:   5 [120/150 (79%)]\tLoss: 0.276877\n",
      "Train Epoch:   5 [128/150 (84%)]\tLoss: 0.394716\n",
      "Train Epoch:   5 [136/150 (89%)]\tLoss: 0.229763\n",
      "Train Epoch:   5 [108/150 (95%)]\tLoss: 0.412154\n",
      "Train Epoch:   6 [  0/150 (0%)]\tLoss: 0.578222\n",
      "Train Epoch:   6 [  8/150 (5%)]\tLoss: 0.996766\n",
      "Train Epoch:   6 [ 16/150 (11%)]\tLoss: 0.111175\n",
      "Train Epoch:   6 [ 24/150 (16%)]\tLoss: 0.444393\n",
      "Train Epoch:   6 [ 32/150 (21%)]\tLoss: 0.411700\n",
      "Train Epoch:   6 [ 40/150 (26%)]\tLoss: 0.411921\n",
      "Train Epoch:   6 [ 48/150 (32%)]\tLoss: 0.523316\n",
      "Train Epoch:   6 [ 56/150 (37%)]\tLoss: 0.289278\n",
      "Train Epoch:   6 [ 64/150 (42%)]\tLoss: 0.686515\n",
      "Train Epoch:   6 [ 72/150 (47%)]\tLoss: 0.892120\n",
      "Train Epoch:   6 [ 80/150 (53%)]\tLoss: 0.444312\n",
      "Train Epoch:   6 [ 88/150 (58%)]\tLoss: 0.280727\n",
      "Train Epoch:   6 [ 96/150 (63%)]\tLoss: 0.553913\n",
      "Train Epoch:   6 [104/150 (68%)]\tLoss: 0.324802\n",
      "Train Epoch:   6 [112/150 (74%)]\tLoss: 0.451541\n",
      "Train Epoch:   6 [120/150 (79%)]\tLoss: 0.467583\n",
      "Train Epoch:   6 [128/150 (84%)]\tLoss: 0.178457\n",
      "Train Epoch:   6 [136/150 (89%)]\tLoss: 0.218041\n",
      "Train Epoch:   6 [108/150 (95%)]\tLoss: 0.294555\n",
      "Train Epoch:   7 [  0/150 (0%)]\tLoss: 0.160858\n",
      "Train Epoch:   7 [  8/150 (5%)]\tLoss: 0.695763\n",
      "Train Epoch:   7 [ 16/150 (11%)]\tLoss: 1.566686\n",
      "Train Epoch:   7 [ 24/150 (16%)]\tLoss: 1.167037\n",
      "Train Epoch:   7 [ 32/150 (21%)]\tLoss: 0.549474\n",
      "Train Epoch:   7 [ 40/150 (26%)]\tLoss: 0.448772\n",
      "Train Epoch:   7 [ 48/150 (32%)]\tLoss: 0.464157\n",
      "Train Epoch:   7 [ 56/150 (37%)]\tLoss: 0.460545\n",
      "Train Epoch:   7 [ 64/150 (42%)]\tLoss: 0.429810\n",
      "Train Epoch:   7 [ 72/150 (47%)]\tLoss: 0.350305\n",
      "Train Epoch:   7 [ 80/150 (53%)]\tLoss: 0.310286\n",
      "Train Epoch:   7 [ 88/150 (58%)]\tLoss: 0.386648\n",
      "Train Epoch:   7 [ 96/150 (63%)]\tLoss: 0.440017\n",
      "Train Epoch:   7 [104/150 (68%)]\tLoss: 0.487351\n",
      "Train Epoch:   7 [112/150 (74%)]\tLoss: 0.535414\n",
      "Train Epoch:   7 [120/150 (79%)]\tLoss: 0.457026\n",
      "Train Epoch:   7 [128/150 (84%)]\tLoss: 0.273457\n",
      "Train Epoch:   7 [136/150 (89%)]\tLoss: 0.326848\n",
      "Train Epoch:   7 [108/150 (95%)]\tLoss: 0.333702\n",
      "Train Epoch:   8 [  0/150 (0%)]\tLoss: 0.325046\n",
      "Train Epoch:   8 [  8/150 (5%)]\tLoss: 0.380603\n",
      "Train Epoch:   8 [ 16/150 (11%)]\tLoss: 0.250172\n",
      "Train Epoch:   8 [ 24/150 (16%)]\tLoss: 0.311440\n",
      "Train Epoch:   8 [ 32/150 (21%)]\tLoss: 0.286276\n",
      "Train Epoch:   8 [ 40/150 (26%)]\tLoss: 0.365713\n",
      "Train Epoch:   8 [ 48/150 (32%)]\tLoss: 0.196013\n",
      "Train Epoch:   8 [ 56/150 (37%)]\tLoss: 0.184018\n",
      "Train Epoch:   8 [ 64/150 (42%)]\tLoss: 0.561032\n",
      "Train Epoch:   8 [ 72/150 (47%)]\tLoss: 1.330958\n",
      "Train Epoch:   8 [ 80/150 (53%)]\tLoss: 0.345978\n",
      "Train Epoch:   8 [ 88/150 (58%)]\tLoss: 0.493483\n",
      "Train Epoch:   8 [ 96/150 (63%)]\tLoss: 0.424803\n",
      "Train Epoch:   8 [104/150 (68%)]\tLoss: 0.303994\n",
      "Train Epoch:   8 [112/150 (74%)]\tLoss: 0.685593\n",
      "Train Epoch:   8 [120/150 (79%)]\tLoss: 0.484189\n",
      "Train Epoch:   8 [128/150 (84%)]\tLoss: 0.373762\n",
      "Train Epoch:   8 [136/150 (89%)]\tLoss: 0.473789\n",
      "Train Epoch:   8 [108/150 (95%)]\tLoss: 0.333284\n",
      "Train Epoch:   9 [  0/150 (0%)]\tLoss: 0.288006\n",
      "Train Epoch:   9 [  8/150 (5%)]\tLoss: 0.499650\n",
      "Train Epoch:   9 [ 16/150 (11%)]\tLoss: 0.312294\n",
      "Train Epoch:   9 [ 24/150 (16%)]\tLoss: 0.765025\n",
      "Train Epoch:   9 [ 32/150 (21%)]\tLoss: 0.288306\n",
      "Train Epoch:   9 [ 40/150 (26%)]\tLoss: 0.570250\n",
      "Train Epoch:   9 [ 48/150 (32%)]\tLoss: 0.463694\n",
      "Train Epoch:   9 [ 56/150 (37%)]\tLoss: 0.339911\n",
      "Train Epoch:   9 [ 64/150 (42%)]\tLoss: 0.334964\n",
      "Train Epoch:   9 [ 72/150 (47%)]\tLoss: 0.280904\n",
      "Train Epoch:   9 [ 80/150 (53%)]\tLoss: 0.484659\n",
      "Train Epoch:   9 [ 88/150 (58%)]\tLoss: 0.674411\n",
      "Train Epoch:   9 [ 96/150 (63%)]\tLoss: 1.501883\n",
      "Train Epoch:   9 [104/150 (68%)]\tLoss: 0.493144\n",
      "Train Epoch:   9 [112/150 (74%)]\tLoss: 0.573631\n",
      "Train Epoch:   9 [120/150 (79%)]\tLoss: 0.451384\n",
      "Train Epoch:   9 [128/150 (84%)]\tLoss: 0.597998\n",
      "Train Epoch:   9 [136/150 (89%)]\tLoss: 0.331390\n",
      "Train Epoch:   9 [108/150 (95%)]\tLoss: 0.439170\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "MODEL_PATH = 'model'\n",
    "\n",
    "# Time to train\n",
    "for e in range(EPOCHS):\n",
    "    model.train()\n",
    "    for i, (data, label) in enumerate(data_loader):\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(data)\n",
    "        loss = F.nll_loss(y_pred, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print('Train Epoch: {:3d} [{:3d}/{:3d} ({:.0f}%)]\\tLoss: {:.6f}'.format(e, \n",
    "                                                                       i * len(data), \n",
    "                                                                       len(data_loader.dataset),\n",
    "                                                                       100. * i / len(data_loader), \n",
    "                                                                       loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YxWwh66w5Pea"
   },
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "5KITNQPAz9uH",
    "outputId": "5fcfc8f3-4844-4f9a-f0a4-2232a4ab1b2b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "# Save the last model\n",
    "torch.save(model, f'{MODEL_PATH}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GQoRvmU25R7R"
   },
   "source": [
    "## Testing Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XdM_vArrFMA5"
   },
   "source": [
    "### Blank Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y0rRfJNeFHyx"
   },
   "outputs": [],
   "source": [
    "# Lets put us in blank paper condition\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qv0rLJANeZcB"
   },
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "vJOQxX36FHce",
    "outputId": "4c14b446-9d1e-40bd-fad7-8b02c695b26b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  import sys\n",
      "predicted: ['setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'virginica', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger = logging.getLogger('iris')\n",
    "\n",
    "\n",
    "## Prediction \n",
    "def handle(event, **kwargs):\n",
    "    # If data is received as json convert to pandas\n",
    "    event = event['data'] if 'data' in event else event\n",
    "    if not isinstance(event, pd.DataFrame):\n",
    "        event = pd.DataFrame.from_dict(event, orient='columns')\n",
    "\n",
    "    # Convert to NDArray\n",
    "    data = torch.from_numpy(event.values.astype('float32'))\n",
    "    \n",
    "    # Retrieve model from disk and use it for predictions\n",
    "    model = torch.load(f'{MODEL_PATH}.pt')\n",
    "    model.eval()\n",
    "    \n",
    "    # Target format convertion\n",
    "    target_dict = {0: 'setosa', 1: 'versicolor', 2:'virginica'}\n",
    "    to_target = np.vectorize(lambda x: target_dict[x])\n",
    "    \n",
    "    return to_target(np.argmax(model(data).detach().numpy(), axis=1)).tolist()\n",
    "\n",
    "## Testing and liveness check\n",
    "def test(data, **kwargs):\n",
    "    pred = handle(data)\n",
    "\n",
    "    logger.warning(f\"predicted: {pred}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "test(iris.data)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pytorch_classification.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
